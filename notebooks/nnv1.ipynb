{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Program Files\\\\Python310\\\\python310.zip', 'C:\\\\Program Files\\\\Python310\\\\DLLs', 'C:\\\\Program Files\\\\Python310\\\\lib', 'C:\\\\Program Files\\\\Python310', 'g:\\\\Work\\\\DS\\\\neural-net-from-scratch\\\\.venv', '', 'g:\\\\Work\\\\DS\\\\neural-net-from-scratch\\\\.venv\\\\lib\\\\site-packages', 'g:\\\\Work\\\\DS\\\\neural-net-from-scratch\\\\.venv\\\\lib\\\\site-packages\\\\win32', 'g:\\\\Work\\\\DS\\\\neural-net-from-scratch\\\\.venv\\\\lib\\\\site-packages\\\\win32\\\\lib', 'g:\\\\Work\\\\DS\\\\neural-net-from-scratch\\\\.venv\\\\lib\\\\site-packages\\\\Pythonwin', 'G:\\\\Work\\\\DS\\\\neural-net-from-scratch', 'G:\\\\Work\\\\DS\\\\neural-net-from-scratch']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to sys.path\n",
    "project_root = Path().resolve().parent  # Adjust as needed to point to the root folder\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(sys.path)  # Check if the path is added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/digit-recognizer/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n",
      "785\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Verify Reading Dataset via MnistDataloader class\n",
    "#\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path  import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#\n",
    "# Set file paths based on added MNIST Datasets\n",
    "#\n",
    "input_path = '../data'\n",
    "data = np.array(pd.read_csv(join(input_path, 'train.csv')))\n",
    "m, n = data.shape\n",
    "print(m)\n",
    "print(n)\n",
    "\n",
    "train_set, dev_set = train_test_split(data, test_size=0.2, random_state=42)\n",
    "X_train = train_set[:100, 1:n]\n",
    "y_train = train_set[:100, 0:1]\n",
    "X_dev = dev_set[:20, 1:n]\n",
    "y_dev = dev_set[:20, 0:1]\n",
    "\n",
    "#\n",
    "# Helper function to show a list of images with their relating titles\n",
    "#\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols) + 1\n",
    "    plt.figure(figsize=(30,20))\n",
    "    index = 1    \n",
    "    for x in zip(images, title_texts):        \n",
    "        image = x[0]        \n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)        \n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);        \n",
    "        index += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images([X_train[0].reshape(28, 28)], [y_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encode Digit Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "digit_encoder = OneHotEncoder()\n",
    "y_train_hot = digit_encoder.fit_transform(y_train).toarray().T\n",
    "y_train_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of Data\n",
    "Handwritten digits in the form of 28 x 28 dimension array with values ranging from 0 (black) to 255 (white) <br> <br>\n",
    "\n",
    "$$dim \\space x_i = 28 * 28 \\newline$$\n",
    "\n",
    "Total Training Samples = 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Layer\n",
    "\n",
    "Dim: 784 x samples, each column is a sample\n",
    "\n",
    "$$ A^{(0)} = \\begin{bmatrix} x_{0, 0} & x_{0, 1} & \\cdots & x_{0, n_{samples}} \\\\ x_{1, 0} & x_{1, 1} & \\cdots & x_{1, n_{samples}} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{783, 0} & x_{783, 1} & \\cdots & x_{783, n_{samples}} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Hidden Layer\n",
    "Dim: 28 x samples, each column is a sample\n",
    "$$ A^{(1)} = \\begin{bmatrix} x_{0, 0} & x_{0, 1} & \\cdots & x_{0, n_{samples}} \\\\ x_{1, 0} & x_{1, 1} & \\cdots & x_{1, n_{samples}} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{27, 0} & x_{27, 1} & \\cdots & x_{27, n_{samples}} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Biases\n",
    "\n",
    "$$A^{(1)} = W^{(1)}A^{(0)} + b^{(1)}$$\n",
    "\n",
    "$\\sigma $ is sigmoid function<br>\n",
    "W is a matrix of dim 28 x 784 <br>\n",
    "b is a matrix of dim 28 x 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Hidden Layer\n",
    "Dim: 28 x samples\n",
    "$$ A^{(2)} = \\begin{bmatrix} x_{0, 0} & x_{0, 1} & \\cdots & x_{0, n_{samples}} \\\\ x_{1, 0} & x_{1, 1} & \\cdots & x_{1, n_{samples}} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{27, 0} & x_{27, 1} & \\cdots & x_{27, n_{samples}} \\end{bmatrix}$$\n",
    "$$A^{(2)} = \\sigma(W^{(2)}A^{(1)} + b^{(2)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Y is matrix of dim 10 x samples representing digits from 0 to 9\n",
    "$$Y = \\begin{bmatrix} y_{0}\\\\ y_{1}\\\\ \\vdots \\\\ y_{9}\\end{bmatrix}$$\n",
    "$$Y = \\sigma(W^{(y)}A^{(2)} + b^{(y)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Data between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.99607843, 0.79215686,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.23921569,\n",
       "        0.43307087],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "A0 = scaler.fit_transform(X_train)\n",
    "A0 = A0.reshape(784 , A0.shape[0])\n",
    "A0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(28, 784)\n",
    "b1 = np.random.rand(28, 1)\n",
    "W2 = np.random.randn(28, 28)\n",
    "b2 = np.random.rand(28, 1)\n",
    "Wy = np.random.randn(10, 28)\n",
    "by = np.random.rand(10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Function for Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.exp(x)/(1 + np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = W1.dot(A0) + b1\n",
    "Z2 = W2.dot(A1) + b2\n",
    "A2 = sigmoid(Z2)\n",
    "Zy = Wy.dot(A2) + by\n",
    "Y = sigmoid(Zy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE Loss\n",
    "The squared error cost function is:\n",
    "\n",
    "  $$C = \\frac{1}{2m} \\sum_{i=1}^m \\sum_{j=1}^n (Y_{\\text{pred}} - Y_{\\text{true}} )^2$$\n",
    "  where $ m $ is the number of training examples, $ Y_{\\text{pred}} = Y $, and $ Y_{\\text{true}} $ is the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.1293917347677165)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = Y.shape[0]\n",
    "m = Y.shape[1]\n",
    "cost = np.sum(np.square(y_train_hot - Y)) / (2 * m)\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "Backpropagation is simply calculating the gradient $ \\frac{\\partial C}{\\partial p}$ where C is the cost function and p is parameter like W or b for each parameter and then using this gradient to perform gradient descent to find optimal parameter values that minimize C. <br><br> $ \\frac{\\partial C}{\\partial p}$ represents how much change in parameter p affects cost C\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the output layer $Y = \\sigma(W^{(y)}A^{(2)} + b^{(y)}) $ <br>\n",
    "$$ \\frac{\\partial C}{\\partial W^{(y)}} = \\frac{\\partial C}{\\partial Y} \\cdot \\frac{\\partial Y}{\\partial Z^{(y)}} \\cdot \\frac{\\partial Z^{(y)}}{\\partial W^{(y)}}  = -\\frac{1}{m} \\big( (Y - Y_{\\text{true}}) \\cdot Y \\cdot (1 - Y) \\big) A^{(2)}$$\n",
    "$$ \\frac{\\partial C}{\\partial b^{(y)}} = \\frac{\\partial C}{\\partial Y} \\cdot \\frac{\\partial Y}{\\partial Z^{(y)}} \\cdot \\frac{\\partial Z^{(y)}}{\\partial b^{(y)}} = -\\frac{1}{m} \\big( (Y - Y_{\\text{true}}) \\cdot Y \\cdot (1 - Y) \\big)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dC_dZy = - ((Y - y_train_hot) * Y * (1-Y))/m\n",
    "dZy_dWy = A2.T # Transpose for matching dimension\n",
    "\n",
    "dC_dWy = np.dot(dC_dZy, dZy_dWy)\n",
    "dC_dby = dC_dZy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2nd Hidden Layer $A^{(2)} = \\sigma(W^{(2)}A^{(1)} + b^{(2)})$\n",
    "$$ \\frac{\\partial C}{\\partial W^{(2)}} = \\frac{\\partial C}{\\partial Y} \\cdot \\frac{\\partial Y}{\\partial Z^{(y)}} \\cdot \\frac{\\partial Z^{(y)}}{\\partial A^{(2)}} \\cdot \\frac{\\partial A^{(2)}}{\\partial Z^{(2)}} \\cdot \\frac{\\partial Z^{(2)}}{\\partial W^{(2)}} = \\frac{1}{m} \\big( (Y - Y_{\\text{true}}) \\cdot Y \\cdot (1 - Y) \\cdot W^{(y)} \\cdot A^{(2)}(1 - A^{(2)}) \\cdot A^{(1)} \\big)$$\n",
    "\n",
    "$$ \\frac{\\partial C}{\\partial b^{(2)}} = \\frac{\\partial C}{\\partial Y} \\cdot \\frac{\\partial Y}{\\partial Z^{(y)}} \\cdot \\frac{\\partial Z^{(y)}}{\\partial A^{(2)}} \\cdot \\frac{\\partial A^{(2)}}{\\partial Z^{(2)}} \\cdot \\frac{\\partial Z^{(2)}}{\\partial b^{(2)}} = \\frac{1}{m} \\big( (Y - Y_{\\text{true}}) \\cdot Y \\cdot (1 - Y) \\cdot W^{(y)} \\cdot A^{(2)}(1 - A^{(2)}) \\big)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dC_dZ2 = np.dot(Wy.T, dC_dZy) * A2 * (1 - A2) \n",
    "\n",
    "dC_dW2 = np.dot(dC_dZ2, A1.T)\n",
    "dC_db2 = dC_dZ2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 1st Hidden Layer $A^{(1)} = W^{(1)}A^{(0)} + b^{(1)}$\n",
    "$$ \\frac{\\partial C}{\\partial W^{(1)}} = \\frac{\\partial C}{\\partial Y} \\cdot \\frac{\\partial Y}{\\partial Z^{(y)}} \\cdot \\frac{\\partial Z^{(y)}}{\\partial A^{(2)}} \\cdot \\frac{\\partial A^{(2)}}{\\partial Z^{(2)}} \\cdot \\frac{\\partial Z^{(2)}}{\\partial A^{(1)}} \\cdot \\frac{\\partial A^{(1)}}{\\partial W^{(1)}} = \\frac{1}{m} \\big( (Y - Y_{\\text{true}}) \\cdot Y \\cdot (1 - Y) \\cdot W^{(y)} \\cdot A^{(2)}(1 - A^{(2)}) \\cdot W^{(2)} \\cdot A^{(0)} \\big)$$\n",
    "\n",
    "$$ \\frac{\\partial C}{\\partial b^{(1)}} = \\frac{\\partial C}{\\partial Y} \\cdot \\frac{\\partial Y}{\\partial Z^{(y)}} \\cdot \\frac{\\partial Z^{(y)}}{\\partial A^{(2)}} \\cdot \\frac{\\partial A^{(2)}}{\\partial Z^{(2)}} \\cdot \\frac{\\partial Z^{(2)}}{\\partial A^{(1)}} \\cdot \\frac{\\partial A^{(1)}}{\\partial W^{(1)}} = \\frac{1}{m} \\big( (Y - Y_{\\text{true}}) \\cdot Y \\cdot (1 - Y) \\cdot W^{(y)} \\cdot A^{(2)}(1 - A^{(2)}) \\cdot W^{(2)} \\big)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dC_dZ1 = np.dot(W2.T, dC_dZ2) * A1 * (1 - A1)  \n",
    "\n",
    "dC_dW1 = np.dot(dC_dZ1, A0.T)\n",
    "dC_db1 = dC_dZ1                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
